library("ggplot2")
library("MASS")
library("class")

class_pred = function(fa_a, fa_p){
  tt = 0
  tf = 0
  ft = 0
  ff = 0
  lv1 = levels(fa_a)[1]
  lv2 = levels(fa_a)[2]
  for (i in 1:length(fa_a)){
    if (fa_a[i]==lv1 && fa_p[i]==lv1){
      tt = tt+1
    } else if (fa_a[i]==lv1 && fa_p[i]==lv2){
      tf = tf+1
    } else if (fa_a[i]==lv2 && fa_p[i]==lv1){
      ft = ft+1
    } else if (fa_a[i]==lv2 && fa_p[i]==lv2){
      ff = ff+1
    }
  }
  desc_str = paste(lv1,"is considered as True and", lv2, "is considered as False")
  col_n = c("True/True", "True/False", "False/True", "False/False")
  row_n = c("Raw Counts", "Proportion")
  desc_vec = c(tt,tf,ft,ff)
  t = tt+tf
  f = ft+ff
  prop_vec = c(tt/t, tf/t, ft/f, ff/f)
  desc_df = rbind.data.frame(desc_vec, prop_vec)
  rownames(desc_df) = row_n
  colnames(desc_df) = col_n
  return (list(desc_str, desc_df))
}

# Data Simulation

# Generate an x,y pair in the unit square so that y>mx*b if label==1 and y<mx*b if label==-1

lin_pair=function(m,b,label){
  # find the part of x that is in the unit square
  x_max = (1-b)/m
  if (!(x_max>=0 && x_max<=1)){
    return(c(NaN, NaN))
  } else {
    x = runif(1, 0, x_max)
    y_true = m*x+b
    if (label==1){
      y = runif(1, y_true,1)
    } else if (label==-1){
      y = runif(1, 0, y_true)
    } else {
      return ("Error, label must be +/- 1")
    }
  }
  return(c(x,y))
}

#Generate a list of n lin_pairs into a datamframe
lin_pair_gen = function(m,b,label,n){
  lin_df = as.data.frame(matrix(0, nrow=n, ncol=2))
  for (i in 1:n){
    l=lin_pair(m,b,label)
    lin_df[i,1]=l[[1]]
    lin_df[i,2]=l[[2]]
  }
  return (lin_df)
}


#Test and graph
l_df = lin_pair_gen(4,0.1,-1, 1000)
colnames(l_df)=c("x","y")
ggplot(data=l_df, aes(x=x,y=y))+geom_point()+ylim(0,1)+xlim(0,1)


#Do the same for a quadratic
quad_pair=function(a,b,c,label){
  # find the part of x that is in the unit square
  x_max = suppressWarnings(b+sqrt(1/a-c))
  if (is.na(x_max)||!(x_max>=0 && x_max<=1)){
    return(c(NaN, NaN))
  } else {
    x = runif(1, 0, x_max)
    y_true = a*(x-b)^2+c
    if (label==1){
      y = runif(1, y_true,1)
    } else if (label==-1){
      y = runif(1, 0, y_true)
    } else {
      return ("Error, label must be +/- 1")
    }
  }
  return(c(x,y))
}

#Generate a list of n quad_pairs into a datamframe
quad_pair_gen = function(a,b,c,label,n){
  quad_df = as.data.frame(matrix(0, nrow=n, ncol=2))
  for (i in 1:n){
    l=quad_pair(a,b,c,label)
    quad_df[i,1]=l[[1]]
    quad_df[i,2]=l[[2]]
  }
  return (quad_df)
}

#Test and graph
q_df = quad_pair_gen(2,-0.1,0.1,1,1000)
colnames(q_df)=c("x","y")
ggplot(data=q_df, aes(x=x,y=y))+geom_point()+ylim(0,1)+xlim(0,1)

# Multivariate distribution (not sure if this works)
mvnorm_pair = function(mu,cov){
  m = mvrnorm(1, mu=mu, Sigma=cov)
  c1 = m[[1]]>1
  c2 = m[[2]]>1
  c3 = m[[1]]<0
  c4 = m[[2]]<0
  while (c1||c2||c3||c4){
    m = mvrnorm(1, mu=mu, Sigma=cov)
    c1 = m[[1]]>1
    c2 = m[[2]]>1
    c3 = m[[1]]<0
    c4 = m[[2]]<0
  }
  return(m)
}

# In p-dimentional space, p*p-1/2 parameters must be estimated for a generative model positing that our two classes of data are generated by multivariate normal distributions

# 100 data points from mvrnorm
cov_1 = matrix(c(0.2,0.1,0.1,0.2), nrow=2)

m_pair_gen = function(mu,cov,n){
  m_df = as.data.frame(matrix(0, nrow=n, ncol=2))
  for (i in 1:n){
    l=mvnorm_pair(mu,cov)
    m_df[i,1]=l[[1]]
    m_df[i,2]=l[[2]]
  }
  return (m_df)
}

m_df_1 = m_pair_gen(c(0.25,0.25), cov_1, 500)
m_df_1$class = rep(1,50)
m_df_2 = m_pair_gen(c(0.75,0.75), cov_1, 500)
m_df_2$class = rep(-1,50)
m_df = rbind(m_df_1, m_df_2)
colnames(m_df)=c("R1", "R2", "class")
ggplot(data=m_df, aes(x=R1, y=R2))+geom_point()

m_lda = lda(class~., data=m_df)
# True/True at 0.62 and False/False at 0.6 with 100 data points
# True/True at 0.65 and False/False at 0.66 with 1000 data points
m_qda = qda(class~., data=m_df)
# True/True at 0.64 and False/False at 0.62 with 100 data points
# True/True at 0.65 and False/False at 0.67 with 1000 data points

m_plda = predict(m_lda, dplyr::select(m_df, R1,R2))
m_pqda = predict(m_qda, dplyr::select(m_df, R1,R2))

class_pred(factor(m_df$class), m_plda$class)
class_pred(factor(m_df$class), m_pqda$class)

# 100 data points from mvrnorm with very different covarience matricies
cov_2 = matrix(c(0.5,0.01,0.01,0.5), nrow=2)
m_df_01 = m_pair_gen(c(0.25,0.25), cov_2, 500)
m_df_01$class = rep(1,50)
m_df_02 = m_pair_gen(c(0.75,0.75), cov_2, 500)
m_df_02$class = rep(-1,50)
m_df_0 = rbind(m_df_01, m_df_02)
colnames(m_df_0)=c("R1", "R2", "class")
ggplot(data=m_df_0, aes(x=R1, y=R2))+geom_point()

m_lda_0 = lda(class~., data=m_df_0)
m_qda_0 = qda(class~., data=m_df_0)

m_plda_0 = predict(m_lda_0, dplyr::select(m_df_0, R1,R2))
m_pqda_0 = predict(m_qda_0, dplyr::select(m_df_0, R1,R2))

class_pred(factor(m_df_0$class), m_plda_0$class)
# True/True at 0.58 and False/False at 0.58 with 100 data points
# No improvement at 1000 data points
class_pred(factor(m_df_0$class), m_pqda_0$class)
# True/True at 0.56 and False/False at 0.66 with 100 data points
# No improvement at 1000 data points


# 200 data points from linear
l_df_1 = lin_pair_gen(1.5,0.2,1, 1000)
l_df_1$class = rep(1,50)
l_df_2 = lin_pair_gen(1.5,0.2,-1, 1000)
l_df_2$class = rep(-1,50)

l_df = rbind(l_df_1, l_df_2)
colnames(l_df)=c("x", "y", "class")

ggplot(data=l_df, aes(x=x, y=y))+geom_point()+ylim(0,1)+xlim(0,1)
l_lda = lda(class~., data=l_df)
l_qda = qda(class~., data=l_df)

lin_l = predict(l_lda, dplyr::select(l_df, x,y))
# 0.909 true true; 0.964 false false at 1000 points each
lin_q = predict(l_qda, dplyr::select(l_df, x,y))
# 0.933 true true; 0.957 false false at 1000 points each